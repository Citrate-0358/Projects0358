{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07ecdbf-edf5-432b-98fb-ce363f84698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from flask) (7.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7896ff11-6929-4a33-9309-d9c25bf6fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5003\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 898, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:49843')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from flask import Flask, request, jsonify\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from validate_email import validate_email\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply the asyncio patch for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models and tokenizer\n",
    "rf_model = joblib.load('random_forest_model.pkl')\n",
    "meta_classifier = joblib.load('meta_classifier_model.pkl')\n",
    "roberta_model = TFRobertaModel.from_pretrained('roberta_model')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta_tokenizer')\n",
    "\n",
    "# Load metadata columns\n",
    "with open('metadata_columns.txt', 'r') as f:\n",
    "    metadata_columns = f.read().splitlines()\n",
    "\n",
    "# Function to validate email with timeout handling\n",
    "def validate_email_with_timeout(email):\n",
    "    try:\n",
    "        return validate_email(email_address=email, check_format=True, check_blacklist=True, check_dns=True, check_smtp=False, smtp_debug=False)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Function to encode texts using RoBERTa tokenizer\n",
    "def encode_texts(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "# Function to generate RoBERTa embeddings\n",
    "def get_roberta_embeddings(encoded_texts, roberta_model, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(encoded_texts['input_ids']), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch = {key: val[i:i+batch_size] for key, val in encoded_texts.items()}\n",
    "        outputs = roberta_model(batch)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].numpy())\n",
    "    return tf.convert_to_tensor(np.concatenate(embeddings, axis=0))\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Data preprocessing\n",
    "    df['sender_email'] = df['sender'].apply(lambda x: re.findall(r'<(.*?)>', x)[0] if re.findall(r'<(.*?)>', x) else x)\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df['domain'] = df['sender_email'].apply(lambda x: x.split('@')[-1])\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    \n",
    "    # Validate emails\n",
    "    df['email_validity'] = df['sender_email'].apply(validate_email_with_timeout)\n",
    "    \n",
    "    # Encode texts\n",
    "    encoded_subjects = encode_texts(df['subject'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "    encoded_bodies = encode_texts(df['body'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings_subjects = get_roberta_embeddings(encoded_subjects, roberta_model, batch_size=16)\n",
    "    embeddings_bodies = get_roberta_embeddings(encoded_bodies, roberta_model, batch_size=16)\n",
    "    embeddings = tf.concat([embeddings_subjects, embeddings_bodies], axis=1)\n",
    "    \n",
    "    # Prepare metadata features\n",
    "    X_meta = df[['domain', 'day_of_week', 'hour', 'email_validity', 'urls']]\n",
    "    X_meta = pd.get_dummies(X_meta)\n",
    "    \n",
    "    # Ensure the columns match those used during training\n",
    "    X_meta = X_meta.reindex(columns=metadata_columns, fill_value=0)\n",
    "    X_meta.columns = X_meta.columns.astype(str)\n",
    "    \n",
    "    # Combine metadata features and embeddings\n",
    "    meta_features = pd.concat([pd.DataFrame(embeddings.numpy()), pd.DataFrame(X_meta.reset_index(drop=True))], axis=1)\n",
    "    meta_features.columns = meta_features.columns.astype(str)\n",
    "    \n",
    "    # Predict using the meta-classifier\n",
    "    y_pred = meta_classifier.predict(meta_features)\n",
    "    \n",
    "    # Send alert to Wazuh\n",
    "    for index, row in df.iterrows():\n",
    "        alert_data = {\n",
    "            \"rule\": {\n",
    "                \"level\": 10,\n",
    "                \"description\": \"Email classified as spam\" if y_pred[index] == 1 else \"Email classified as not spam\",\n",
    "            },\n",
    "            \"agent\": {\n",
    "                \"id\": \"001\",\n",
    "                \"name\": \"EmailClassifier\",\n",
    "            },\n",
    "            \"manager\": {\n",
    "                \"name\": \"LocalManager\"\n",
    "            },\n",
    "            \"id\": \"123456\",\n",
    "            \"full_log\": row.to_json(),\n",
    "        }\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        response = requests.post('http://wazuh-manager:55000/alerts', headers=headers, json=alert_data)\n",
    "        print(f\"Alert sent to Wazuh: {response.status_code}\")\n",
    "    \n",
    "    return jsonify({'predictions': y_pred.tolist()})\n",
    "\n",
    "# Run the Flask app on a different port\n",
    "app.run(port=5003, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572364ad-188b-4243-9ffc-108ecf549f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
