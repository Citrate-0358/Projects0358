{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f53932-295b-4716-9bcc-d1a19ca88310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: transformers in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (4.37.0)\n",
      "Requirement already satisfied: tensorflow in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: py3-validate-email in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (1.0.5.post1)\n",
      "Requirement already satisfied: joblib in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: tqdm in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: filelock in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.25.1)\n",
      "Requirement already satisfied: setuptools in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: dnspython~=2.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from py3-validate-email) (2.6.1)\n",
      "Requirement already satisfied: idna~=3.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from py3-validate-email) (3.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn transformers tensorflow py3-validate-email joblib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abdd2f6-f298-4721-afaa-391e63f162b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathos in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (0.3.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pathos) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pathos) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pathos) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pathos) (0.70.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pathos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9228f6-287d-4c02-9692-bee61d88cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abd/.pyenv/versions/3.8.10/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import tensorflow as tf\n",
    "from validate_email import validate_email\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0452656-fdd3-48aa-b7fc-9cb3339629a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the DataFrame from 'validated_emails.csv'.\n",
      "Columns after validation: ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls', 'sender_email', 'domain', 'day_of_week', 'hour', 'email_validity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from validate_email import validate_email\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Function to validate email with timeout handling\n",
    "def validate_email_with_timeout(email):\n",
    "    try:\n",
    "        return validate_email(email_address=email, check_format=True, check_blacklist=True, check_dns=True, check_smtp=False, smtp_debug=False)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def validate_emails():\n",
    "    try:\n",
    "        # Try to load the saved DataFrame\n",
    "        df = pd.read_csv('validated_emails.csv')\n",
    "        df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "        print(\"Loaded the DataFrame from 'validated_emails.csv'.\")\n",
    "    except FileNotFoundError:\n",
    "        # Load dataset\n",
    "        df = pd.read_csv('CEAS_08.csv')\n",
    "        df = df.head(50000)\n",
    "\n",
    "        # Data preprocessing\n",
    "        df['sender_email'] = df['sender'].apply(lambda x: re.findall(r'<(.*?)>', x)[0] if re.findall(r'<(.*?)>', x) else x)\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "        df = df.dropna(subset=['date'])\n",
    "\n",
    "        df['domain'] = df['sender_email'].apply(lambda x: x.split('@')[-1])\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        df['hour'] = df['date'].dt.hour\n",
    "        df['urls'] = df['body'].apply(lambda x: 1 if re.search(r'http[s]?://', str(x)) else 0)\n",
    "\n",
    "        print(\"Validating emails...\")\n",
    "        start_time = time.time()\n",
    "        with Pool(processes=4) as pool:\n",
    "            df['email_validity'] = list(tqdm(pool.imap(validate_email_with_timeout, df['sender_email']), total=len(df)))\n",
    "        end_time = time.time()\n",
    "        print(f\"Email validation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Save the validated DataFrame\n",
    "        df.to_csv('validated_emails.csv', index=False)\n",
    "        print(\"Saved the validated DataFrame to 'validated_emails.csv'.\")\n",
    "\n",
    "    print(\"Columns after validation:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "df = validate_emails()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cfe511-6afe-4981-a9bc-b1a7cac59e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the DataFrame from 'validated_emails.csv'.\n",
      "Columns after loading dataset: ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls', 'sender_email', 'domain', 'day_of_week', 'hour', 'email_validity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset():\n",
    "    df = pd.read_csv('validated_emails.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "    print(\"Loaded the DataFrame from 'validated_emails.csv'.\")\n",
    "    print(\"Columns after loading dataset:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "df = load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338696e1-78eb-40de-849b-736d62d76104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 21:52:43.607752: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-05-15 21:52:43.607780: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-15 21:52:43.607785: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-15 21:52:43.607817: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-15 21:52:43.607838: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating RoBERTa embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|████████████████| 1713/1713 [02:24<00:00, 11.83it/s]\n",
      "Generating embeddings: 100%|██████████████████| 734/734 [01:01<00:00, 12.02it/s]\n",
      "Generating embeddings: 100%|████████████████| 1713/1713 [02:21<00:00, 12.09it/s]\n",
      "Generating embeddings: 100%|██████████████████| 734/734 [01:00<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings generated in 408.37 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "# Function to encode texts using RoBERTa tokenizer\n",
    "def encode_texts(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "# Function to get RoBERTa embeddings\n",
    "def get_roberta_embeddings(encoded_texts, roberta_model, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(encoded_texts['input_ids']), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch = {key: val[i:i+batch_size] for key, val in encoded_texts.items()}\n",
    "        outputs = roberta_model(batch)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].numpy())\n",
    "    return tf.convert_to_tensor(np.concatenate(embeddings, axis=0))\n",
    "\n",
    "def train_model(df):\n",
    "    # Ensure all necessary columns are present\n",
    "    required_columns = ['domain', 'day_of_week', 'hour', 'email_validity', 'urls']\n",
    "    for column in required_columns:\n",
    "        if column not in df.columns:\n",
    "            raise KeyError(f\"'{column}' not found in DataFrame columns. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Train-test split before tokenization\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, df['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "    encoded_subjects_train = encode_texts(X_train['subject'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "    encoded_bodies_train = encode_texts(X_train['body'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "    encoded_subjects_test = encode_texts(X_test['subject'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "    encoded_bodies_test = encode_texts(X_test['body'].astype(str).tolist(), tokenizer, max_length=64)\n",
    "\n",
    "    X_meta_train = X_train[required_columns]\n",
    "    X_meta_test = X_test[required_columns]\n",
    "    \n",
    "    X_meta_train = pd.get_dummies(X_meta_train)\n",
    "    X_meta_test = pd.get_dummies(X_meta_test)\n",
    "    \n",
    "    X_meta_test = X_meta_test.reindex(columns = X_meta_train.columns, fill_value=0)\n",
    "    X_meta_train.columns = X_meta_train.columns.astype(str)\n",
    "    X_meta_test.columns = X_meta_test.columns.astype(str)\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_meta_train, y_train)\n",
    "\n",
    "    roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "    print(\"Generating RoBERTa embeddings...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_embeddings_subjects = get_roberta_embeddings(encoded_subjects_train, roberta_model, batch_size=16)\n",
    "    test_embeddings_subjects = get_roberta_embeddings(encoded_subjects_test, roberta_model, batch_size=16)\n",
    "\n",
    "    train_embeddings_bodies = get_roberta_embeddings(encoded_bodies_train, roberta_model, batch_size=16)\n",
    "    test_embeddings_bodies = get_roberta_embeddings(encoded_bodies_test, roberta_model, batch_size=16)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"RoBERTa embeddings generated in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    train_embeddings = tf.concat([train_embeddings_subjects, train_embeddings_bodies], axis=1)\n",
    "    test_embeddings = tf.concat([test_embeddings_subjects, test_embeddings_bodies], axis=1)\n",
    "\n",
    "    meta_features_train = pd.concat([pd.DataFrame(train_embeddings.numpy()), pd.DataFrame(X_meta_train.reset_index(drop=True))], axis=1)\n",
    "    meta_features_test = pd.concat([pd.DataFrame(test_embeddings.numpy()), pd.DataFrame(X_meta_test.reset_index(drop=True))], axis=1)\n",
    "\n",
    "    meta_features_train.columns = meta_features_train.columns.astype(str)\n",
    "    meta_features_test.columns = meta_features_test.columns.astype(str)\n",
    "\n",
    "    meta_classifier = LogisticRegression(max_iter=1000)\n",
    "    meta_classifier.fit(meta_features_train, y_train)\n",
    "\n",
    "    joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "    joblib.dump(meta_classifier, 'meta_classifier_model.pkl')\n",
    "    roberta_model.save_pretrained('roberta_model')\n",
    "    tokenizer.save_pretrained('roberta_tokenizer')\n",
    "\n",
    "    # Save columns used in metadata training\n",
    "    with open('metadata_columns.txt', 'w') as f:\n",
    "        for column in X_meta_train.columns:\n",
    "            f.write(f\"{column}\\n\")\n",
    "\n",
    "    return rf_model, meta_classifier, roberta_model, tokenizer, X_test, y_test, meta_features_test\n",
    "\n",
    "rf_model, meta_classifier, roberta_model, tokenizer, X_test, y_test, meta_features_test = train_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02e6d6e-36d9-4956-8e62-b64e37349fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.13%\n",
      "F1 Score: 0.99\n",
      "Recall: 0.99\n",
      "Confusion Matrix:\n",
      "[[5135   68]\n",
      " [  34 6505]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(meta_classifier, meta_features_test, y_test):\n",
    "    y_pred = meta_classifier.predict(meta_features_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    return accuracy, f1, recall, cm\n",
    "\n",
    "accuracy, f1, recall, cm = evaluate_model(meta_classifier, meta_features_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e47b6-7a26-4773-a27e-282cf642c3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
